import cv2
import os
import requests
import json
from datetime import datetime, timedelta
import argparse
from typing import List, Dict, Any
import time
import logging
from logging.handlers import RotatingFileHandler

# é…ç½®logging
from datetime import datetime
# ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
log_filename = f"auto_label_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        logging.StreamHandler(),
        # è¾“å‡ºåˆ°æ–‡ä»¶ï¼ŒæŒ‰å¤§å°æ»šåŠ¨ï¼Œæœ€å¤§10MBï¼Œä¿ç•™5ä¸ªå¤‡ä»½
        RotatingFileHandler(
            log_filename,
            maxBytes=10*1024*1024,
            backupCount=5,
            encoding='utf-8'
        )
    ]
)

# è®°å½•æ—¥å¿—æ–‡ä»¶å
logging.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {log_filename}")

class AutoLabeler:
    def __init__(self, model_api_url: str, api_key: str = None, prompt: str = None, timeout: int = 30):
        """åˆå§‹åŒ–è‡ªåŠ¨æ ‡æ³¨å™¨
        
        Args:
            model_api_url: å¤§æ¨¡å‹APIåœ°å€
            api_key: APIå¯†é’¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
            prompt: è‡ªå®šä¹‰æç¤ºè¯
            timeout: HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.model_api_url = model_api_url
        self.api_key = api_key
        self.session = requests.Session()
        # è®¾ç½®é»˜è®¤è¶…æ—¶æ—¶é—´
        self.timeout = timeout
        # é»˜è®¤æç¤ºè¯
        self.default_prompt = "æ£€æµ‹å›¾ä¸­ç‰©ä½“ï¼Œè¿”å›JSONï¼š{\"detections\":[{\"label\":\"ç±»åˆ«\",\"confidence\":0.9,\"bbox\":[x1,y1,x2,y2]}]}"
        # ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯æˆ–é»˜è®¤æç¤ºè¯
        self.prompt = prompt if prompt else self.default_prompt
    
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """è°ƒç”¨LMStudioçš„qwen3-vl-8bæ¨¡å‹APIåˆ†æå›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤§æ¨¡å‹è¿”å›çš„åˆ†æç»“æœ
        """
        import base64
        
        headers = {
            "Content-Type": "application/json"
        }
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
        
        # ç¡®ä¿APIåœ°å€ä»¥æ­£ç¡®çš„ç«¯ç‚¹ç»“å°¾
        api_endpoint = self.model_api_url
        # å¦‚æœAPIåœ°å€ä»¥/v1ç»“å°¾ï¼Œæ·»åŠ /chat/completionsç«¯ç‚¹
        if api_endpoint.endswith("/v1"):
            api_endpoint = f"{api_endpoint}/chat/completions"
        # å¦‚æœAPIåœ°å€æ˜¯æ ¹è·¯å¾„ï¼Œæ·»åŠ å®Œæ•´ç«¯ç‚¹
        elif not api_endpoint.endswith("/chat/completions"):
            api_endpoint = f"{api_endpoint.rstrip('/')}/v1/chat/completions"
        
        # è¯»å–å›¾åƒå¹¶å‹ç¼©ï¼Œå‡å°‘base64ç¼–ç åçš„å¤§å°
        import cv2
        import numpy as np
        
        # è¯»å–å›¾åƒ
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        # å‹ç¼©å›¾åƒï¼ˆè°ƒæ•´å¤§å°ï¼‰
        max_size = 640  # æœ€å¤§è¾¹é•¿
        h, w = img.shape[:2]
        if max(h, w) > max_size:
            scale = max_size / max(h, w)
            new_w = int(w * scale)
            new_h = int(h * scale)
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        # è½¬æ¢ä¸ºJPEGæ ¼å¼ï¼Œé™ä½è´¨é‡
        _, buffer = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 70])
        image_base64 = base64.b64encode(buffer).decode("utf-8")
        
        # æ„å»ºLMStudioå…¼å®¹çš„è¯·æ±‚ä½“
        payload = {
            "model": "qwen/qwen3-vl-8b",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": self.prompt
                        }
                    ]
                }
            ],
            "temperature": 0.0,
            "response_format": {
                "type": "text"
            }
        }
        
        # å‘é€è¯·æ±‚
        try:
            response = self.session.post(api_endpoint, headers=headers, json=payload, timeout=self.timeout)
            response.raise_for_status()
            result = response.json()
            
            # è§£æLMStudioè¿”å›çš„ç»“æœ
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                # å°è¯•è§£æJSONå†…å®¹
                try:
                    # å»é™¤Markdownæ ¼å¼æ ‡è®°
                    if content.startswith('```json'):
                        content = content[7:]  # ç§»é™¤å¼€å¤´çš„```json
                    if content.endswith('```'):
                        content = content[:-3]  # ç§»é™¤ç»“å°¾çš„```
                    content = content.strip()  # å»é™¤é¦–å°¾ç©ºç™½
                    
                    return json.loads(content)
                except json.JSONDecodeError:
                    logging.error(f"æ— æ³•è§£ææ¨¡å‹è¿”å›çš„JSON: {content}")
                    return {"detections": []}
            return {"detections": []}
        except Exception as e:
            logging.error(f"åˆ†æå›¾åƒ {image_path} å¤±è´¥: {e}")
            logging.error(f"ä½¿ç”¨çš„APIç«¯ç‚¹: {api_endpoint}")
            return {"detections": []}
    
    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        import glob
        try:
            # æ¸…ç†æ‰€æœ‰ä¸´æ—¶å¸§æ–‡ä»¶
            temp_files = glob.glob("frame_*.jpg")
            if temp_files:
                for temp_file in temp_files:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                logging.info(f"âœ… æ¸…ç†äº† {len(temp_files)} ä¸ªä¸´æ—¶æ–‡ä»¶")
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def render_detections(self, image_path: str, detections: List[Dict[str, Any]]) -> str:
        """å°†æ£€æµ‹ç»“æœæ¸²æŸ“åˆ°å›¾åƒä¸Š
        
        Args:
            image_path: åŸå§‹å›¾åƒè·¯å¾„
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            æ¸²æŸ“åçš„å›¾åƒè·¯å¾„
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        # å®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆä¸åŒç±»åˆ«ä½¿ç”¨ä¸åŒé¢œè‰²ï¼‰
        colors = {
            "person": (0, 255, 0),
            "car": (255, 0, 0),
            "bicycle": (0, 0, 255),
            "dog": (255, 255, 0),
            "cat": (255, 0, 255),
            "äºº": (0, 255, 0),
            "è½¦": (255, 0, 0),
            "è‡ªè¡Œè½¦": (0, 0, 255),
            "ç‹—": (255, 255, 0),
            "çŒ«": (255, 0, 255),
            "default": (0, 255, 255)
        }
        
        # æ¸²æŸ“æ£€æµ‹æ¡†å’Œæ ‡ç­¾
        for detection in detections:
            # è§£ææ£€æµ‹ç»“æœ
            label = detection.get("label", "unknown")
            confidence = detection.get("confidence", 0.0)
            bbox = detection.get("bbox", [0, 0, 0, 0])
            
            # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
            x1, y1, x2, y2 = map(int, bbox)
            
            # è·å–é¢œè‰²
            color = colors.get(label, colors["default"])
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
            label_text = f"{label}: {confidence:.2f}"
            
            # ä½¿ç”¨PILåº“æ¸²æŸ“ä¸­æ–‡
            try:
                from PIL import Image, ImageDraw, ImageFont
                import numpy as np
                
                # è½¬æ¢ä¸ºPILå›¾åƒ
                img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(img_pil)
                
                # åŠ è½½é»˜è®¤ä¸­æ–‡å­—ä½“æˆ–æŒ‡å®šå­—ä½“æ–‡ä»¶
                try:
                    # å°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ä¸­æ–‡å­—ä½“
                    font = ImageFont.truetype("simhei.ttf", 16)
                except IOError:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨PILé»˜è®¤å­—ä½“
                    font = ImageFont.load_default()
                
                # ç»˜åˆ¶æ–‡æœ¬
                text_x = x1
                text_y = y1 - 20 if y1 > 20 else y1 + 20
                draw.text((text_x, text_y), label_text, font=font, fill=tuple(color[::-1]))
                
                # è½¬æ¢å›OpenCVå›¾åƒ
                image = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
            except Exception as e:
                # å¦‚æœPILæ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨OpenCVé»˜è®¤æ¸²æŸ“ï¼ˆå¯èƒ½ä¼šæœ‰ä¹±ç ï¼‰
                print(f"ä¸­æ–‡æ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¸²æŸ“: {e}")
                cv2.putText(image, label_text, (x1, y1 - 10 if y1 > 10 else y1 + 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # ä¿å­˜æ¸²æŸ“åçš„å›¾åƒ
        rendered_path = image_path.replace(".jpg", "_labeled.jpg")
        cv2.imwrite(rendered_path, image)
        return rendered_path
    
    def process_video(self, video_path: str, output_dir: str, frame_interval: int = 1):
        """å¤„ç†è§†é¢‘å®Œæ•´æµç¨‹ï¼Œæ”¯æŒæœ¬åœ°è§†é¢‘å’ŒRTSPæµï¼ŒåŒæ­¥å¤„ç†æ¨¡å¼
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–RTSPæµåœ°å€
            output_dir: è¾“å‡ºç›®å½•
            frame_interval: æŠ½å¸§é—´éš”
        """
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†è§†é¢‘æµ: {video_path}")
        logging.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logging.info(f"â±ï¸  æŠ½å¸§é—´éš”: {frame_interval}")
        logging.info(f"ğŸ“… å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logging.info("ğŸ’¡ æç¤º: æŒ‰ Ctrl+C å¯éšæ—¶ä¸­æ–­å¤„ç†")
        logging.info("=" * 60)
        
        # åˆ›å»ºä¸¤ä¸ªè¾“å‡ºç›®å½•ï¼šä¸€ä¸ªä¿å­˜åŸå§‹æœªæ¸²æŸ“å¸§ï¼Œä¸€ä¸ªä¿å­˜æ¸²æŸ“åçš„å¸§
        raw_frames_dir = os.path.join(output_dir, "raw_frames")
        labeled_frames_dir = os.path.join(output_dir, "labeled_frames")
        os.makedirs(raw_frames_dir, exist_ok=True)
        os.makedirs(labeled_frames_dir, exist_ok=True)
        logging.info(f"ğŸ“ åŸå§‹å¸§ç›®å½•: {raw_frames_dir}")
        logging.info(f"ğŸ“ æ¸²æŸ“å¸§ç›®å½•: {labeled_frames_dir}")
        
        # åˆå§‹åŒ–å˜é‡
        cap = None
        frame_count = 0
        processed_count = 0
        is_rtsp = video_path.lower().startswith("rtsp://")
        max_reconnect_attempts = 50  # æœ€å¤§é‡è¿æ¬¡æ•°ï¼Œ0è¡¨ç¤ºæ— é™é‡è¯•
        reconnect_delay = 5  # é‡è¿å»¶è¿Ÿï¼ˆç§’ï¼‰
        reconnect_count = 0
        last_status_time = datetime.now()  # ä¸Šæ¬¡è¾“å‡ºçŠ¶æ€çš„æ—¶é—´
        status_interval = 60  # çŠ¶æ€è¾“å‡ºé—´éš”ï¼ˆç§’ï¼‰
        
        try:
            while True:
                try:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰“å¼€æˆ–é‡æ–°æ‰“å¼€è§†é¢‘æµ
                    if cap is None or not cap.isOpened():
                        if reconnect_count > 0:
                            logging.info(f"ğŸ”„ å°è¯•é‡æ–°è¿æ¥ RTSP æµ... (å°è¯• {reconnect_count}/{max_reconnect_attempts if max_reconnect_attempts > 0 else 'æ— é™'})")
                        else:
                            logging.info(f"ğŸ“¡ æ‰“å¼€è§†é¢‘æµ: {video_path}")
                        
                        # æ‰“å¼€è§†é¢‘æˆ–RTSPæµ
                        cap = cv2.VideoCapture(video_path)
                        if not cap.isOpened():
                            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æµ: {video_path}")
                        
                        if reconnect_count > 0:
                            logging.info("âœ… RTSP æµé‡æ–°è¿æ¥æˆåŠŸ")
                            reconnect_count = 0  # é‡ç½®é‡è¿è®¡æ•°
                    
                    # è¯»å–ä¸€å¸§
                    cap.grab()  # åªæŠ“å–å¸§ï¼Œä¸è§£ç ï¼Œæé«˜å“åº”é€Ÿåº¦
                    ret, frame = cap.retrieve()  # è§£ç å¸§
                    
                    if not ret:
                        if is_rtsp:
                            # RTSPæµä¸­æ–­ï¼Œå°è¯•é‡è¿
                            logging.info(f"âš ï¸  RTSP æµä¸­æ–­ï¼Œ{reconnect_delay}ç§’åå°è¯•é‡è¿...")
                            
                            # å…³é—­å½“å‰è§†é¢‘æµ
                            if cap is not None:
                                cap.release()
                                cap = None
                            
                            # å¢åŠ é‡è¿è®¡æ•°
                            reconnect_count += 1
                            
                            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•°
                            if max_reconnect_attempts > 0 and reconnect_count > max_reconnect_attempts:
                                logging.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•° ({max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿")
                                break
                            
                            # ç­‰å¾…é‡è¿å»¶è¿Ÿ
                            time.sleep(reconnect_delay)
                            continue  # è·³è¿‡å½“å‰å¾ªç¯ï¼Œå°è¯•é‡æ–°è¿æ¥
                        else:
                            # æœ¬åœ°è§†é¢‘æ–‡ä»¶ç»“æŸ
                            logging.info("âœ… è§†é¢‘æµè¯»å–å®Œæˆ")
                            break
                    
                    # æŒ‰ç…§æŒ‡å®šé—´éš”å¤„ç†å¸§
                    if frame_count % frame_interval == 0:
                        logging.info(f"ğŸ”„ å¤„ç†å¸§ #{frame_count}")
                        
                        # å®šä¹‰ç»Ÿä¸€çš„æ–‡ä»¶å
                        frame_filename = f"frame_{frame_count:06d}.jpg"
                        
                        # ä¿å­˜ä¸´æ—¶å¸§ç”¨äºå¤„ç†
                        temp_frame_path = f"temp_{frame_filename}"
                        cv2.imwrite(temp_frame_path, frame)
                        
                        try:
                            # åˆ†æå›¾åƒï¼ˆåŒæ­¥å¤„ç†ï¼Œé˜»å¡ç­‰å¾…ç»“æœï¼‰
                            result = self.analyze_image(temp_frame_path)
                            
                            # è§£ææ£€æµ‹ç»“æœ
                            detections = result.get("detections", [])
                            if isinstance(detections, dict):
                                detections = [detections]
                            
                            # ä»…å½“æ£€æµ‹åˆ°è‡³å°‘ä¸€ä¸ªç›®æ ‡æ—¶ï¼Œæ‰ä¿å­˜å›¾ç‰‡
                            if detections and len(detections) > 0:
                                logging.info(f"âœ… æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
                                
                                # ä¿å­˜åŸå§‹æœªæ¸²æŸ“å¸§åˆ°raw_framesç›®å½•
                                raw_frame_path = os.path.join(raw_frames_dir, frame_filename)
                                cv2.imwrite(raw_frame_path, frame)
                                logging.info(f"âœ… å·²ä¿å­˜åŸå§‹å¸§: {raw_frame_path}")
                                
                                # æ¸²æŸ“æ£€æµ‹ç»“æœ
                                rendered_path = self.render_detections(temp_frame_path, detections)
                                
                                # ç§»åŠ¨æ¸²æŸ“åçš„å¸§åˆ°æœ€ç»ˆç›®å½•ï¼Œä¿æŒä¸åŸå§‹å¸§ç›¸åŒçš„æ–‡ä»¶å
                                final_path = os.path.join(labeled_frames_dir, frame_filename)
                                os.rename(rendered_path, final_path)
                                logging.info(f"âœ… å·²ä¿å­˜æ ‡æ³¨å¸§: {final_path}")
                                processed_count += 1
                            else:
                                logging.info(f"â„¹ï¸  æœªæ£€æµ‹åˆ°ç›®æ ‡ï¼Œè·³è¿‡ä¿å­˜")
                        except KeyboardInterrupt:
                            logging.info("\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
                            # åˆ é™¤æœªå¤„ç†å®Œçš„ä¸´æ—¶æ–‡ä»¶
                            if os.path.exists(temp_frame_path):
                                os.remove(temp_frame_path)
                            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚å¤„ç†
                        
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_frame_path):
                            os.remove(temp_frame_path)
                    
                    frame_count += 1
                    
                    # å®šæœŸè¾“å‡ºçŠ¶æ€ä¿¡æ¯
                    current_time = datetime.now()
                    if (current_time - last_status_time).total_seconds() >= status_interval:
                        # è®¡ç®—è¿è¡Œæ—¶é•¿
                        elapsed = current_time - start_time
                        # è®¡ç®—å¤„ç†é€Ÿåº¦
                        fps = processed_count / elapsed.total_seconds() if elapsed.total_seconds() > 0 else 0
                        
                        logging.info(f"[{current_time.strftime('%Y-%m-%d %H:%M:%S')}] "
                              f"è¿è¡Œæ—¶é•¿: {str(elapsed).split('.')[0]} | "
                              f"æ€»å¸§æ•°: {frame_count} | "
                              f"å·²å¤„ç†: {processed_count}å¸§ | "
                              f"å¤„ç†é€Ÿåº¦: {fps:.2f}å¸§/ç§’")
                        last_status_time = current_time
                    
                    # çŸ­æš‚ä¼‘çœ ï¼Œæé«˜ä¸­æ–­å“åº”é€Ÿåº¦
                    time.sleep(0.001)
                    
                except KeyboardInterrupt:
                    logging.info("\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚å¤„ç†
                except Exception as e:
                    if is_rtsp:
                        # RTSPæµå‡ºç°å¼‚å¸¸ï¼Œå°è¯•é‡è¿
                        logging.warning(f"âš ï¸  RTSP æµå¼‚å¸¸: {e}ï¼Œ{reconnect_delay}ç§’åå°è¯•é‡è¿...")
                        
                        # å…³é—­å½“å‰è§†é¢‘æµ
                        if cap is not None:
                            cap.release()
                            cap = None
                        
                        # å¢åŠ é‡è¿è®¡æ•°
                        reconnect_count += 1
                        
                        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•°
                        if max_reconnect_attempts > 0 and reconnect_count > max_reconnect_attempts:
                            logging.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•° ({max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿")
                            raise
                        
                        # ç­‰å¾…é‡è¿å»¶è¿Ÿ
                        time.sleep(reconnect_delay)
                        continue  # è·³è¿‡å½“å‰å¾ªç¯ï¼Œå°è¯•é‡æ–°è¿æ¥
                    else:
                        # æœ¬åœ°è§†é¢‘æ–‡ä»¶å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
                        raise
        
        except KeyboardInterrupt:
            logging.info("\nğŸ›‘ æ­£åœ¨åœæ­¢å¤„ç†...")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†å¼‚å¸¸: {e}")
        finally:
            # ç¡®ä¿è§†é¢‘æµè¢«é‡Šæ”¾
            if cap is not None and cap.isOpened():
                cap.release()
                logging.info("âœ… è§†é¢‘æµå·²é‡Šæ”¾")
            
            # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files()
        
        # è®¡ç®—ç»“æŸæ—¶é—´å’Œæ€»è¿è¡Œæ—¶é•¿
        end_time = datetime.now()
        total_elapsed = end_time - start_time
        
        logging.info(f"\n" + "=" * 60)
        logging.info(f"ğŸ“Š å®Œæ•´å¤„ç†ç»Ÿè®¡:")
        logging.info(f"ğŸ“… å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logging.info(f"ğŸ“… ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logging.info(f"â±ï¸  æ€»è¿è¡Œæ—¶é•¿: {str(total_elapsed).split('.')[0]}")
        logging.info(f"ğŸ“ˆ æ€»å¸§æ•°: {frame_count}")
        logging.info(f"âœ… å·²å¤„ç†: {processed_count}å¸§")
        logging.info(f"ğŸ“Š å¤„ç†æ¯”ä¾‹: {processed_count / frame_count * 100:.1f}%" if frame_count > 0 else "ğŸ“Š å¤„ç†æ¯”ä¾‹: 0%")
        logging.info(f"âš¡ å¹³å‡é€Ÿåº¦: {processed_count / total_elapsed.total_seconds():.2f}å¸§/ç§’" if total_elapsed.total_seconds() > 0 else "âš¡ å¹³å‡é€Ÿåº¦: 0å¸§/ç§’")
        logging.info(f"ğŸ“ è¾“å‡ºç›®å½•: {labeled_frames_dir}")
        logging.info("=" * 60)
        logging.info("âœ… å¤„ç†å·²åœæ­¢")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨è§†é¢‘æ ‡æ³¨å·¥å…· - é€‚é…LMStudio qwen3-vl-8bæ¨¡å‹")
    parser.add_argument("--video", required=True, help="è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–RTSPæµåœ°å€")
    parser.add_argument("--output", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--interval", type=int, default=1, help="æŠ½å¸§é—´éš”")
    parser.add_argument("--model-api", default="http://192.168.1.105:1234/v1", help="å¤§æ¨¡å‹APIåœ°å€ï¼Œé»˜è®¤é€‚é…LMStudio: http://192.168.1.105:1234")
    parser.add_argument("--api-key", help="APIå¯†é’¥")
    parser.add_argument("--prompt", help="è‡ªå®šä¹‰æç¤ºè¯ï¼Œç”¨äºæŒ‡å¯¼å¤§æ¨¡å‹æ£€æµ‹ç‰©ä½“")
    parser.add_argument("--timeout", type=int, default=30, help="HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤30ç§’")
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()
    
    # è®°å½•ä½¿ç”¨çš„é…ç½®
    if args.prompt:
        logging.info(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯: {args.prompt}")
    else:
        logging.info(f"ğŸ“ ä½¿ç”¨é»˜è®¤æç¤ºè¯")
    logging.info(f"â±ï¸  HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´: {args.timeout} ç§’")
    
    # åˆ›å»ºè‡ªåŠ¨æ ‡æ³¨å™¨
    labeler = AutoLabeler(args.model_api, args.api_key, args.prompt, args.timeout)
    
    # å¤„ç†è§†é¢‘
    labeler.process_video(args.video, args.output, args.interval)
